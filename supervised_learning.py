# -*- coding: utf-8 -*-
"""Supervised learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VaLoz3Wcsapqv8yg8HkiQtnlCrjh92bD

# Supervised learning (neural network)
"""

import numpy as np
import pandas as pd

from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print('The user has loaded the data file "{name}" with a length of {length} bits'.format(
      name=fn, length=len(uploaded[fn])))

"""#Attribute Information

* age
* sex
* chest pain type (4 values)
* resting blood pressure
* serum cholestoral in mg/dl
* fasting blood sugar > 120 mg/dl
* resting electrocardiographic results (values 0,1,2)
* maximum heart rate achieved
* exercise induced angina
* oldpeak = ST depression induced by exercise relative to rest
* the slope of the peak exercise ST segment
* number of major vessels (0-3) colored by flourosopy
* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
"""

#Loading data
dataset = pd.read_csv('heart.csv')

import matplotlib.pyplot as plt

#Columns and rows in the data
print(dataset.shape)
#Top 10 rows
print(dataset.head(10))
#Main data matrices
print(dataset.describe())
#Class distribution
from pylab import rcParams
rcParams['figure.figsize'] = 10, 7
print(dataset.groupby('target').size())
dataset['target'].value_counts().plot.bar()

print('The proportion of classes:')
print(dataset['target'].value_counts() / len(dataset))

#Data types
print(dataset.info())

#Number of missing data points per column
missing_values_count = dataset.isnull().sum()
print(missing_values_count)

#Histograms
dataset.hist(figsize=(15,12),bins = 20)
plt.title("Distribution features")
plt.show()

"""#Pre-processing of data"""

X = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values

from sklearn import model_selection

splits = model_selection.train_test_split(X, y, test_size=0.25, random_state=0)
X_train, X_test, y_train, y_test = splits
print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)

X_train[0]

#The function scales the data
from sklearn.preprocessing import StandardScaler 
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

X_train[0]

"""#Construction of a neural network


"""

import keras
keras.__version__
from keras import models
from keras import layers

#Two hidden layers and 13 artifacts input vector
model = models.Sequential()
model.add(layers.Dense(12, activation='relu', input_shape=(13,)))
model.add(layers.Dense(12, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

print(model.summary())

#Validation on 150 samples
x_val = X_train[:150]
partial_x_train = X_train[150:]

y_val = y_train[:150]
partial_y_train = y_train[150:]

history = model.fit(partial_x_train,partial_y_train,epochs=75,batch_size=12,validation_data=(x_val, y_val))

"""#Analysis of the results"""

history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

acc = history.history['accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

#The parameter 'bo' defines the dashed line in the form of blue dots.
plt.plot(epochs, loss, 'bo', label='Training loss')
#The parameter 'b' defines a solid blue line.
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Loss of training and validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf() #Cleaning up the drawing
acc_values = history_dict['accuracy']

plt.plot(epochs, acc, 'bo', label='Accuracy of training')
plt.title('Accuracy of training')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

from matplotlib import pyplot as plt
plt.plot(history.history['accuracy'],'green')
plt.plot(history.history['loss'],'red')
plt.title('Accuracy-loss model')
plt.xlabel('Epochs')
plt.legend(['Accuracy','Loss function'])
plt.show()

#Predict test suite results
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

y_pred = model.predict(X_test)
y_pred = (y_pred>0.5) #Because the output is a probability
cm = confusion_matrix(y_test,y_pred)
accuracy = accuracy_score(y_test,y_pred)
print(classification_report(y_test, y_pred))
print("Classification (neural network):")
print("Accuracy = ", accuracy)
print(cm)